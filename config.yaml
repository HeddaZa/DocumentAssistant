llm:
  provider: ollama  # Options: 'ollama' or 'openai'
  model: gemma:7b
  temperature: 0.7
  max_tokens: 2000

paths:
  data_dir: data
  pdfs_dir: data/pdfs
  pictures_dir: data/Pictures

database:
  path: data/extractions.db

# GraphRAG configuration (future feature)
graphrag:
  enabled: false
  vector_store: chroma
  embedding_model: sentence-transformers/all-MiniLM-L6-v2
  chunk_size: 512

# API configuration (future feature)
api:
  host: 0.0.0.0
  port: 8000
  cors_origins:
    - http://localhost:3000

# Legacy ollama configuration (kept for backward compatibility)
ollama:
 name: gemma
 model: gemma:7b